# Awesome Multi-armed Bandit

A curated list of resources about **multi-armed bandit** (**MAB**).

> Attention: this repository is still under construction! :construction:
>
> If you have any ideas for this repository, please create a new issue. :raised_hands:

## Introduction

The multi-armed bandit problem is a classic **reinforcement learning** problem that exemplifies the exploration-exploitation tradeoff dilemma.

## Setup

If you want to run the jupyter notebooks in this repository, read through the following instructions in this section. Otherwise, ignore this section. You can still view the result of the notebooks by following the links listed in corresponding README files.

### Install conda

[conda.io](https://conda.io)

### Create the environment from the text file and activate it

```shell
$ conda create --name mab_env --file mab_env.txt
$ conda activate mab_env
```

### Start jupyter-lab

```shell
$ jupyter-lab
```

Then open the url in your browser and enjoy the GUI offered by jupyter-lab!

## Books

- [Multi-armed Bandit Allocation Indices](https://www.amazon.com/Multi-armed-Bandit-Allocation-Indices-Gittins/dp/0470670029)
- [Bandit Algorithms for Website Optimization](http://shop.oreilly.com/product/0636920027393.do)
- [Introduction to Multi-Armed Bandits](https://arxiv.org/abs/1904.07272)

## Papers

- The 1979 paper by Gittins: [Bandit Processes and Dynamic Allocation Indices](https://people.eecs.berkeley.edu/~russell/classes/cs294/s11/readings/Gittins:1979.pdf)
- [Scaling Multi-Armed Bandit Algorithms](https://dbis.ipd.kit.edu/download/S-MAB_FOUCHE_KDD19.pdf)
- [Multi-Armed Bandits with Correlated Arms](https://arxiv.org/abs/1911.03959)

## Websites

- [https://banditalgs.com/](https://banditalgs.com/)

## Practical projects

Get your hands dirty by doing some projects (simulations)!

- [A simple project by Prof. Ziyu Shao](./bandit_project): [Live Jupyter Notebook](https://nbviewer.jupyter.org/github/DerekDick/awesome-multi-armed-bandit/blob/master/bandit_project/three_armed_bandit.ipynb)
